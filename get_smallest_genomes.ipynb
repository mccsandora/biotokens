{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://ftp.ncbi.nlm.nih.gov/genomes/refseq/\"\n",
    "\n",
    "domains = [\n",
    "    'archaea', 'bacteria', 'fungi', 'invertebrate',\n",
    "    'plant', 'protozoa', 'vertebrate_mammalian',\n",
    "    'vertebrate_other', 'viral'\n",
    "]\n",
    "\n",
    "# no assembly_summary.txt files for plastid, plasmid, or mitochondrion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and cleaned archaea assembly summary.\n",
      "Downloaded and cleaned bacteria assembly summary.\n",
      "Downloaded and cleaned fungi assembly summary.\n",
      "Downloaded and cleaned invertebrate assembly summary.\n",
      "Downloaded and cleaned plant assembly summary.\n",
      "Downloaded and cleaned protozoa assembly summary.\n",
      "Downloaded and cleaned vertebrate_mammalian assembly summary.\n",
      "Downloaded and cleaned vertebrate_other assembly summary.\n",
      "Downloaded and cleaned viral assembly summary.\n"
     ]
    }
   ],
   "source": [
    "assembly_dir = \"assembly_summaries\"\n",
    "genome_sequences_dir = \"genome_sequences\"\n",
    "os.makedirs(genome_sequences_dir, exist_ok=True)\n",
    "\n",
    "def download_assembly_summary(domain):\n",
    "    url = f\"{base_url}{domain}/assembly_summary.txt\"\n",
    "    local_path = os.path.join(assembly_dir, f\"{domain}_assembly_summary.txt\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        lines = response.text.splitlines()\n",
    "        if lines[0].startswith(\"##\"):\n",
    "            lines = lines[1:] \n",
    "        if lines[0].startswith(\"#\"):\n",
    "            lines[0] = lines[0][1:]  \n",
    "        with open(local_path, 'w') as file:\n",
    "            file.write(\"\\n\".join(lines))\n",
    "        print(f\"downloaded and cleaned the {domain} assembly summary.\")\n",
    "    except Exception as e:\n",
    "        print(f\"error downloading {domain} assembly summary: {e}\")\n",
    "\n",
    "for domain in domains:\n",
    "    download_assembly_summary(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to /Users/tiananoll-walker/Documents/biotokens/smallest_genomes.xlsx\n"
     ]
    }
   ],
   "source": [
    "#this code reads the assembly summary file for each domain, then checnks for required columns and converts size cols to numeric vals. Then filters\n",
    "# for complete genomes and finds the smallest\n",
    "\n",
    "\n",
    "def process_assembly_summary(domain):\n",
    "    local_path = os.path.join(assembly_dir, f\"{domain}_assembly_summary.txt\")\n",
    "    try:\n",
    "        df = pd.read_csv(local_path, sep='\\t', dtype=str)\n",
    "        \n",
    "        required_columns = ['assembly_accession', 'assembly_level', 'genome_size', 'genome_size_ungapped', 'ftp_path', 'organism_name']\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            df['genome_size'] = pd.to_numeric(df['genome_size'], errors='coerce')\n",
    "            df['genome_size_ungapped'] = pd.to_numeric(df['genome_size_ungapped'], errors='coerce')\n",
    "            complete_genomes = df[df['assembly_level'] == 'Complete Genome']\n",
    "            if not complete_genomes.empty:\n",
    "                smallest_genome = complete_genomes.loc[complete_genomes['genome_size_ungapped'].idxmin()]\n",
    "                return smallest_genome\n",
    "        else:\n",
    "            print(f\"missing columns in {domain}: {set(required_columns) - set(df.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error processing {domain}: {e}\")\n",
    "    return None\n",
    "\n",
    "smallest_genomes_list = []\n",
    "for domain in domains:\n",
    "    smallest_genome = process_assembly_summary(domain)\n",
    "    if smallest_genome is not None:\n",
    "        smallest_genomes_list.append(smallest_genome)\n",
    "\n",
    "smallest_genomes_df = pd.DataFrame(smallest_genomes_list)\n",
    "\n",
    "\n",
    "output_excel_path = \"/Users/tiananoll-walker/Documents/biotokens/smallest_genomes.xlsx\"\n",
    "if not smallest_genomes_df.empty:\n",
    "    smallest_genomes_df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"saved to {output_excel_path}\")\n",
    "else:\n",
    "    print(\"no data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded assembly report for Nanobdella aerobiophila\n",
      "Downloaded assembly report for Candidatus Karelsulcia muelleri\n",
      "Downloaded assembly report for Malassezia restricta\n",
      "Downloaded assembly report for Caenorhabditis elegans\n",
      "Downloaded assembly report for Ostreococcus lucimarinus CCE9901\n",
      "Downloaded assembly report for Theileria orientalis strain Shintoku\n",
      "Downloaded assembly report for Mugil cephalus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "assembly_reports_dir = \"assembly_reports\"\n",
    "genome_sequences_dir = \"genome_sequences\"\n",
    "os.makedirs(assembly_reports_dir, exist_ok=True)\n",
    "os.makedirs(genome_sequences_dir, exist_ok=True)\n",
    "\n",
    "organismnames = {\n",
    "    \"Nanobdella aerobiophila\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/023/169/545/GCF_023169545.1_ASM2316954v1/GCF_023169545.1_ASM2316954v1_assembly_report.txt\",\n",
    "    \"Candidatus Karelsulcia muelleri\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/016/889/585/GCF_016889585.1_ASM1688958v1/GCF_016889585.1_ASM1688958v1_assembly_report.txt\",\n",
    "    \"Malassezia restricta\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/290/485/GCF_003290485.1_ASM329048v1/GCF_003290485.1_ASM329048v1_assembly_report.txt\",\n",
    "    \"Caenorhabditis elegans\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_assembly_report.txt\",\n",
    "    \"Ostreococcus lucimarinus CCE9901\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/092/065/GCF_000092065.1_ASM9206v1/GCF_000092065.1_ASM9206v1_assembly_report.txt\",\n",
    "    \"Theileria orientalis strain Shintoku\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/740/895/GCF_000740895.1_ASM74089v1/GCF_000740895.1_ASM74089v1_assembly_report.txt\",\n",
    "    \"Bubalus bubalis\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/019/923/935/GCF_019923935.1_NDDB_SH_1/GCF_019923935.1_NDDB_SH_1_assembly_report.txt\",\n",
    "    \"Mugil cephalus\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/022/458/985/GCF_022458985.1_CIBA_Mcephalus_1.1/GCF_022458985.1_CIBA_Mcephalus_1.1_assembly_report.txt\",\n",
    "    \"Rice yellow mottle virus satellite\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/839/085/GCF_000839085.1_ViralProj14152/GCF_000839085.1_ViralProj14152_assembly_report.txt\"\n",
    "}\n",
    "\n",
    "def download_assembly_report(organism_name, url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        file_path = os.path.join(assembly_reports_dir, f\"{organism_name.replace(' ', '_')}_assembly_report.txt\")\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded assembly report for {organism_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download assembly report for {organism_name}. Status code: {response.status_code}\")\n",
    "        print(f\"URL: {url}\")\n",
    "\n",
    "for organism_name, url in organismnames.items():\n",
    "    download_assembly_report(organism_name, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded genome sequence for Nanobdella aerobiophila: GCF_files/GCF_023169545.1_ASM2316954v1_genomic.fna.gz\n",
      "cleaned sequence for Nanobdella aerobiophila already exists. Skipping extraction.\n",
      "downloaded genome sequence for Candidatus Karelsulcia muelleri: GCF_files/GCF_016889585.1_ASM1688958v1_genomic.fna.gz\n",
      "cleaned sequence for Candidatus Karelsulcia muelleri already exists. Skipping extraction.\n",
      "downloaded genome sequence for Malassezia restricta: GCF_files/GCF_003290485.1_ASM329048v1_genomic.fna.gz\n",
      "cleaned sequence for Malassezia restricta already exists. Skipping extraction.\n",
      "downloaded genome sequence for Caenorhabditis elegans: GCF_files/GCF_000002985.6_WBcel235_genomic.fna.gz\n",
      "cleaned sequence for Caenorhabditis elegans already exists. Skipping extraction.\n",
      "downloaded genome sequence for Ostreococcus lucimarinus CCE9901: GCF_files/GCF_000092065.1_ASM9206v1_genomic.fna.gz\n",
      "cleaned sequence for Ostreococcus lucimarinus CCE9901 already exists. Skipping extraction.\n",
      "downloaded genome sequence for Theileria orientalis strain Shintoku: GCF_files/GCF_000740895.1_ASM74089v1_genomic.fna.gz\n",
      "cleaned sequence for Theileria orientalis strain Shintoku already exists. Skipping extraction.\n",
      "downloaded genome sequence for Rice yellow mottle virus satellite: GCF_files/GCF_000839085.1_ViralProj14152_genomic.fna.gz\n",
      "cleaned sequence for Rice yellow mottle virus satellite already exists. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gzip\n",
    "import requests\n",
    "\n",
    "\n",
    "gcf_files_path = \"GCF_files\"\n",
    "genome_sequences_dir = \"genome_sequences\"\n",
    "os.makedirs(assembly_reports_dir, exist_ok=True)\n",
    "os.makedirs(genome_sequences_dir, exist_ok=True)\n",
    "\n",
    "organisms = {\n",
    "    \"Nanobdella aerobiophila\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/023/169/545/GCF_023169545.1_ASM2316954v1/GCF_023169545.1_ASM2316954v1_genomic.fna.gz\",\n",
    "    \"Candidatus Karelsulcia muelleri\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/016/889/585/GCF_016889585.1_ASM1688958v1/GCF_016889585.1_ASM1688958v1_genomic.fna.gz\",\n",
    "    \"Malassezia restricta\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/290/485/GCF_003290485.1_ASM329048v1/GCF_003290485.1_ASM329048v1_genomic.fna.gz\",\n",
    "    \"Caenorhabditis elegans\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_genomic.fna.gz\",\n",
    "    \"Ostreococcus lucimarinus CCE9901\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/092/065/GCF_000092065.1_ASM9206v1/GCF_000092065.1_ASM9206v1_genomic.fna.gz\",\n",
    "    \"Theileria orientalis strain Shintoku\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/740/895/GCF_000740895.1_ASM74089v1/GCF_000740895.1_ASM74089v1_genomic.fna.gz\",\n",
    "    \"Mugil cephalus\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/022/458/985/GCF_022458985.1_CIBA_Mcephalus_1.1/GCF_022458985.1_CIBA_Mcephalus_1.1_genomic.fna.gz\",\n",
    "    \"Rice yellow mottle virus satellite\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/839/085/GCF_000839085.1_ViralProj14152/GCF_000839085.1_ViralProj14152_genomic.fna.gz\",\n",
    "    \"Bubalus bubalis\": \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/019/923/935/GCF_019923935.1_NDDB_SH_1/GCF_019923935.1_NDDB_SH_1_genomic.fna.gz\"\n",
    "\n",
    "}\n",
    "\n",
    "def download_genome_sequence(organism_name, url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        local_path = os.path.join(gcf_files_path, url.split('/')[-1])\n",
    "        with open(local_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"downloaded genome sequence for {organism_name}: {local_path}\")\n",
    "        return local_path\n",
    "    else:\n",
    "        print(f\"failed to download genome sequence for {organism_name}. status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_and_clean_sequence(file_path, organism_name):\n",
    "    base_filename = f\"{organism_name.replace(' ', '_')}\"\n",
    "    cleaned_filename = f\"{genome_sequences_dir}/{base_filename}_cleaned.txt\"\n",
    "    \n",
    "    if os.path.exists(cleaned_filename):\n",
    "        print(f\"cleaned sequence for {organism_name} already exists. Skipping extraction.\")\n",
    "        return cleaned_filename\n",
    "    \n",
    "    with gzip.open(file_path, 'rt') as infile:\n",
    "        lines = infile.readlines()\n",
    "    \n",
    "    sequence = ''.join([line.strip() for line in lines if not line.startswith(\">\")])\n",
    "    cleaned_sequence = re.sub(r'[^ACGTacgt]', '', sequence).upper()\n",
    "    \n",
    "    with open(cleaned_filename, 'w') as outfile:\n",
    "        outfile.write(cleaned_sequence)\n",
    "    \n",
    "    print(f\"cleaned sequence saved to {cleaned_filename}\")\n",
    "    return cleaned_filename\n",
    "\n",
    "for organism_name, url in organisms.items():\n",
    "    file_path = download_genome_sequence(organism_name, url)\n",
    "    if file_path:\n",
    "        extract_and_clean_sequence(file_path, organism_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random genome of length 1000000 saved to genome_sequences\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "genome_sequences_dir = \"genome_sequences\"\n",
    "\n",
    "def generate_random_genome(length):\n",
    "    return ''.join(random.choices('ACGT', k=length))\n",
    "\n",
    "random_genome_length = 1000000\n",
    "random_genome = generate_random_genome(random_genome_length)\n",
    "\n",
    "random_genome_file = os.path.join(genome_sequences_dir, \"random_genome.txt\")\n",
    "with open(random_genome_file, 'w') as f:\n",
    "    f.write(random_genome)\n",
    "\n",
    "print(f\"random genome of length {random_genome_length} saved to {genome_sequences_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ostreococcus_lucimarinus_CCE9901_cleaned.txt: Length = 13204888, Shannon Entropy = 1.968334374463055\n",
      "Theileria_orientalis_strain_Shintoku_cleaned.txt: Length = 9006764, Shannon Entropy = 1.9792812782136475\n",
      "Candidatus_Karelsulcia_muelleri_cleaned.txt: Length = 142117, Shannon Entropy = 1.8322368021416449\n",
      "random_genome.txt: Length = 1000000, Shannon Entropy = 1.9999951310060542\n",
      "Plasmodium_falciparum_cleaned.txt: Length = 2925236, Shannon Entropy = 1.700437913566233\n",
      "Arabidopsis_thaliana_cleaned.txt: Length = 119482427, Shannon Entropy = 1.9431467139424183\n",
      "Escherichia_coli_K-12_cleaned.txt: Length = 4641652, Shannon Entropy = 1.9998190013576105\n",
      "Saccharomyces_cerevisiae_cleaned.txt: Length = 230218, Shannon Entropy = 1.9664766384439507\n",
      "Rice_yellow_mottle_virus_satellite_cleaned.txt: Length = 220, Shannon Entropy = 1.9408982701656994\n",
      "Malassezia_restricta_cleaned.txt: Length = 7369627, Shannon Entropy = 1.9907365513928101\n",
      "Caenorhabditis_elegans_cleaned.txt: Length = 100286401, Shannon Entropy = 1.937934065817183\n",
      "Mugil_cephalus_cleaned.txt: Length = 634627260, Shannon Entropy = 1.9809663778407824\n",
      "Halobacterium_salinarum_NRC-1_cleaned.txt: Length = 2014239, Shannon Entropy = 1.905323387374254\n",
      "Nanobdella_aerobiophila_cleaned.txt: Length = 668961, Shannon Entropy = 1.8054655786727367\n",
      "results saved to small_n_random_genome_sequences_lengths_and_entropy.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def shannon_entropy(s):\n",
    "    frequency = Counter(s)\n",
    "    probabilities = [freq / len(s) for freq in frequency.values()]\n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "lengths = []\n",
    "entropies = []\n",
    "\n",
    "# calculate length and entropy for cleaned sequences\n",
    "for filename in os.listdir(genome_sequences_dir):\n",
    "    if filename.endswith(\"_cleaned.txt\") or filename == \"random_genome.txt\":\n",
    "        filepath = os.path.join(genome_sequences_dir, filename)\n",
    "        with open(filepath, 'r') as f:\n",
    "            sequence = f.read()\n",
    "        genome_length = len(sequence)\n",
    "        genome_entropy = shannon_entropy(sequence)\n",
    "        lengths.append(genome_length)\n",
    "        entropies.append(genome_entropy)\n",
    "        print(f'{filename}: Length = {genome_length}, Shannon Entropy = {genome_entropy}')\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Filename\": [filename.replace(\"_cleaned.txt\", \"\").replace(\".txt\", \"\") for filename in os.listdir(genome_sequences_dir) if filename.endswith(\"_cleaned.txt\") or filename == \"random_genome.txt\"],\n",
    "    \"Length\": lengths,\n",
    "    \"Shannon Entropy\": entropies\n",
    "})\n",
    "\n",
    "results_filename = \"small_n_random_genome_sequences_lengths_and_entropy.xlsx\"\n",
    "results_df.to_excel(results_filename, index=False)\n",
    "print(f\"results saved to {results_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
