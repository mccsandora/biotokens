{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook to loop (download - process - delete) through all genomes in refseq for a certain domain of life :\n",
    "# https://ftp.ncbi.nlm.nih.gov/genomes/refseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "from collections import Counter\n",
    "from EntropyHub import ApEn\n",
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test this notebook with the assembly_summary_test.txt in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then,read the assembly_summary.txt file\n",
    "local_directory = '/Users/celia/Desktop/biotokens/ncbi/assembly'\n",
    "file_name = 'assembly_summary_orgs.txt'\n",
    "file_path = os.path.join(local_directory, file_name)\n",
    "df = pd.read_csv(file_path, sep='\\t', comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataframe:\n",
      "Index(['assembly_accession', 'bioproject', 'biosample', 'wgs_master',\n",
      "       'refseq_category', 'taxid', 'species_taxid', 'organism_name',\n",
      "       'infraspecific_name', 'isolate', 'version_status', 'assembly_level',\n",
      "       'release_type', 'genome_rep', 'seq_rel_date', 'asm_name',\n",
      "       'asm_submitter', 'gbrs_paired_asm', 'paired_asm_comp', 'ftp_path',\n",
      "       'excluded_from_refseq', 'relation_to_type_material',\n",
      "       'asm_not_live_date', 'assembly_type', 'group', 'genome_size',\n",
      "       'genome_size_ungapped', 'gc_percent', 'replicon_count',\n",
      "       'scaffold_count', 'contig_count', 'annotation_provider',\n",
      "       'annotation_name', 'annotation_date', 'total_gene_count',\n",
      "       'protein_coding_gene_count', 'non_coding_gene_count', 'pubmed_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print column names to verify\n",
    "print(\"Column names in the dataframe:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Verify column names\n",
    "assembly_level_col = 'assembly_level'\n",
    "ftp_path_col = 'ftp_path'\n",
    "assembly_accession_col = 'assembly_accession'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon entropy of the string 'aaabbbbcc' is: 1.5304930567574824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to convert DNA sequence to numerical values\n",
    "def dna_to_numerical(dna_seq):\n",
    "    mapping = {'A': 1, 'C': 2, 'G': 3, 'T': 4}\n",
    "    return [mapping[nuc] for nuc in dna_seq if nuc in mapping]\n",
    "\n",
    "def shannon_entropy(s):\n",
    "    # Count the frequency of each symbol in the string\n",
    "    frequency = Counter(s)\n",
    "    # Calculate the probability of each symbol\n",
    "    probabilities = [freq / len(s) for freq in frequency.values()]\n",
    "    # Calculate the Shannon entropy\n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "# Example usage\n",
    "string = \"aaabbbbcc\"\n",
    "entropy = shannon_entropy(string)\n",
    "print(f\"Shannon entropy of the string '{string}' is: {entropy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gffs(gff_file_path, genome_file_path, output_file_path, biotype = 'CDS'):\n",
    "    # Load genome sequence\n",
    "    genome_dict = SeqIO.to_dict(SeqIO.parse(genome_file_path, \"fasta\"))\n",
    "\n",
    "    # Dictionary to store CDS features by their Parent ID\n",
    "    biotypes_by_parent = defaultdict(list)\n",
    "\n",
    "    # Parse the GFF file\n",
    "    with open(gff_file_path) as file:\n",
    "        for line in file:\n",
    "            if not line.startswith(\"#\"):\n",
    "                parts = line.strip().split('\\t')\n",
    "                if parts[2] == biotype:\n",
    "                    # Extract relevant data\n",
    "                    seq_id = parts[0]\n",
    "                    start = int(parts[3]) - 1  # GFF is 1-based, converting to 0-based\n",
    "                    end = int(parts[4])\n",
    "                    strand = parts[6]\n",
    "                    attributes = parts[8]\n",
    "\n",
    "                    # Extract Parent ID\n",
    "                    parent_id = None\n",
    "                    for attribute in attributes.split(';'):\n",
    "                        if attribute.startswith(\"Parent=\"):\n",
    "                            parent_id = attribute.split('=')[1]\n",
    "                            break\n",
    "\n",
    "                    if parent_id:\n",
    "                        # Append biotypes feature details\n",
    "                        biotypes_by_parent[parent_id].append((seq_id, start, end, strand))\n",
    "\n",
    "    # Function to join CDS sequences\n",
    "    def join_biotypes(biotypes_list):\n",
    "        biotypes_list.sort(key=lambda x: x[1])  # Sort by start position\n",
    "        joined_seq = Seq('')\n",
    "        sequence_id = ''\n",
    "        for seq_id, start, end, strand in biotypes_list:\n",
    "            seq = genome_dict[seq_id].seq[start:end]\n",
    "            if strand == '-':\n",
    "                seq = seq.reverse_complement()\n",
    "            joined_seq += seq\n",
    "            sequence_id = seq_id\n",
    "        return joined_seq, sequence_id\n",
    "\n",
    "    # Join biotypes for each Parent ID\n",
    "    biotype_records = []\n",
    "    for parent_id, biotypes_list in biotypes_by_parent.items():\n",
    "        joined_biotypes_seq, seq_id = join_biotypes(biotypes_list)\n",
    "        biotype_record = SeqRecord(joined_biotypes_seq, id=seq_id, description=f\"biotype: {biotype}\")\n",
    "        biotype_records.append(biotype_record)\n",
    "\n",
    "    # Save to a FASTA file\n",
    "    SeqIO.write(biotype_records, output_file, \"fasta\")\n",
    "    return True, len(biotype_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing assembly_accession: GCF_000005845.2\n",
      "GCF_000005845.2_ASM584v2 CDS True 4305\n",
      "GCF_000005845.2_ASM584v2 ncRNA True 98\n",
      "Analyzing assembly_accession: GCF_000006805.1\n",
      "GCF_000006805.1_ASM680v1 CDS True 2697\n",
      "GCF_000006805.1_ASM680v1 ncRNA True 0\n",
      "Analyzing assembly_accession: GCF_000002765.6\n",
      "GCF_000002765.6_GCA_000002765 CDS True 5354\n",
      "GCF_000002765.6_GCA_000002765 ncRNA True 55\n",
      "Analyzing assembly_accession: GCF_000146045.2\n",
      "GCF_000146045.2_R64 CDS True 6027\n",
      "GCF_000146045.2_R64 ncRNA True 22\n",
      "Excel file created: /Users/celia/Desktop/biotokens/ncbi/assembly/ncbi_assembly_genom.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store new columns\n",
    "sequence_counts = []\n",
    "ents = []\n",
    "biotypes = ['CDS', 'ncRNA']\n",
    "biotypes_sequence_count_dict = {}\n",
    "# Check if the expected columns exist\n",
    "if assembly_level_col in df.columns and ftp_path_col in df.columns:\n",
    "    # Iterate over each row in the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        if row[assembly_level_col] == 'Complete Genome':\n",
    "            assembly_accession = row[assembly_accession_col]\n",
    "            biotypes_sequence_count_dict[assembly_accession] = {}\n",
    "            ftp_path = row[ftp_path_col]\n",
    "            file_name = ftp_path.split('/')[-1]\n",
    "            fna_gz = f\"{file_name}_genomic.fna.gz\"\n",
    "            gff_gz = f\"{file_name}_genomic.gff.gz\"\n",
    "\n",
    "            # Print assembly_accession to track progress\n",
    "            print(f\"Analyzing assembly_accession: {assembly_accession}\")\n",
    "\n",
    "            # Download the gz files\n",
    "            for file in [fna_gz, gff_gz]:\n",
    "                local_file_path = os.path.join(local_directory, f\"{file.split('.gz')[0]}\")\n",
    "                # Open the stream and decompress on the fly\n",
    "                with requests.get(f\"{ftp_path}/{file}\", stream=True) as response:\n",
    "                    response.raise_for_status()  # Check for request errors\n",
    "                    with open(local_file_path, 'wb') as output_file:\n",
    "                        with gzip.GzipFile(fileobj=response.raw) as f:\n",
    "                            shutil.copyfileobj(f, output_file)\n",
    "            \n",
    "            for biotype in biotypes:\n",
    "                output_file = os.path.join(local_directory, f\"{file_name}_joined_{biotype}_sequences.fasta\")\n",
    "                gff_local_path = os.path.join(local_directory, f\"{gff_gz.split('.gz')[0]}\")\n",
    "                fna_local_path = os.path.join(local_directory, f\"{fna_gz.split('.gz')[0]}\")\n",
    "                result, biotype_sequences_count = read_gffs(gff_local_path, fna_local_path, output_file_path, biotype)\n",
    "                print(file_name, biotype, result, biotype_sequences_count)\n",
    "                biotypes_sequence_count_dict[assembly_accession][biotype] = biotype_sequences_count\n",
    "            # Clean up the downloaded file\n",
    "            # for file in [fna_gz, gff_gz]:\n",
    "            #     local_file_path = os.path.join(local_directory, f\"{file.split('.gz')[0]}\")\n",
    "            #     os.remove(local_file_path)\n",
    "\n",
    "            # Append the calculated values to the lists\n",
    "            sequence_counts.append(sequence_count)\n",
    "            ents.append(genome_ent)\n",
    "        else:\n",
    "            # If the row is not \"Complete Genome\", skip it\n",
    "            continue\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    dict_df = pd.DataFrame(biotypes_sequence_count_dict).T  # Transpose to align keys as index\n",
    "    dict_df.index.name = 'assembly_accession'  # Set the index name to match the key column in df\n",
    "    dict_df.reset_index(inplace=True)  # Convert index to a column\n",
    "\n",
    "    # Filter the dataframe to only include rows with \"Complete Genome\"\n",
    "    df_complete_genome = df[df[assembly_level_col] == 'Complete Genome'].copy()\n",
    "\n",
    "    # Add the new columns to the filtered dataframe\n",
    "    # Merge the original DataFrame with the new DataFrame\n",
    "    merged_df = pd.merge(df_complete_genome, dict_df, on='assembly_accession', how='left')\n",
    "\n",
    "    # Save the filtered dataframe to an Excel file\n",
    "    output_file_path = '/Users/celia/Desktop/biotokens/ncbi/assembly/ncbi_assembly_genom.xlsx'\n",
    "    merged_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Excel file created: {output_file_path}\")\n",
    "else:\n",
    "    print(f\"Expected columns '{assembly_level_col}' and/or '{ftp_path_col}' not found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".apen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
